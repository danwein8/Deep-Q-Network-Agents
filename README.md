# Deep-Q-Network-Agents
Final project for Deep Learning independent study at CUNY Lehman. A few DQN Agents that beat different types of games.<br><br>
## Discrete Mountain Car Agent <br>
- beats classic control game Mountain Car with a discrete action space <br>
## Acrobot Agent <br>
- beats classic control game Acrobot with a discrete action space <br>
## CartPole Agent <br>
- beats classic control game CartPole with a discrete action space. <br>
## Pendulum Agent <br>
- Pendulum agent created with `ActionDiscretizeWrapper()` wrapper to make the continuous action space discrete allowing the DQN agent to work <br>
### Info
- The DNQ Agents can only train on environments with a discreet action space, not a continuous action space.
- Action space is the range of moves you can make as the player.
